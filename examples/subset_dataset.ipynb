{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2028402d-9351-471e-82f2-4d9a5e5df719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path if needed\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885fc14a-308a-4190-99a1-0dd16859dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "from experanto.datasets import ChunkDataset\n",
    "from experanto.dataloaders import get_multisession_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdae3976-97ef-48e1-86ad-23e4058a2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  global_sampling_rate: null\n",
      "  global_chunk_size: null\n",
      "  add_behavior_as_channels: false\n",
      "  replace_nans_with_means: false\n",
      "  cache_data: false\n",
      "  out_keys:\n",
      "  - screen\n",
      "  - responses\n",
      "  - eye_tracker\n",
      "  - treadmill\n",
      "  - timestamps\n",
      "  normalize_timestamps: true\n",
      "  modality_config:\n",
      "    screen:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      valid_condition:\n",
      "        tier: train\n",
      "      offset: 0\n",
      "      sample_stride: 1\n",
      "      include_blanks: true\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "        Resize:\n",
      "          _target_: torchvision.transforms.v2.Resize\n",
      "          size:\n",
      "          - 144\n",
      "          - 256\n",
      "      interpolation:\n",
      "        rescale: true\n",
      "        rescale_size:\n",
      "        - 144\n",
      "        - 256\n",
      "    responses:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 8\n",
      "      chunk_size: 16\n",
      "      offset: 0.0\n",
      "      transforms:\n",
      "        normalization: standardize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "    eye_tracker:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      offset: 0\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "    treadmill:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      offset: 0\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "dataloader:\n",
      "  batch_size: 16\n",
      "  shuffle: true\n",
      "  num_workers: 2\n",
      "  pin_memory: true\n",
      "  drop_last: true\n",
      "  prefetch_factor: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30422f76-e0ce-4ccf-9aaa-212489cfe067",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.modality_config.screen.include_blanks = True\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"train\"}\n",
    "cfg.dataloader.num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553daf92-07bf-49b4-86b5-11331f49856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at /data/dynamic29513-3-5-Video-full/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "\n",
    "paths = [\"/data/dynamic29513-3-5-Video-full\"]\n",
    "train_dl = get_multisession_dataloader(paths, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eebba7b-eb53-44a5-be94-ace0af38096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.experiment import Experiment\n",
    "from experanto.configs import DEFAULT_MODALITY_CONFIG\n",
    "\n",
    "# Define the path to your experiment data\n",
    "root_folder = '/data/dynamic29513-3-5-Video-full'\n",
    "\n",
    "# Initialize the experiment\n",
    "experiment = Experiment(root_folder, modality_config=DEFAULT_MODALITY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc49e43-67ef-48f8-bc3f-2418a16adf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from experanto.intervals import TimeInterval\n",
    "\n",
    "# Access the screen device to find the timestamps of the first 10 frames\n",
    "screen_device = experiment.devices['screen']\n",
    "\n",
    "# Assuming screen timestamps are available and sorted\n",
    "# Get the start and end time for the first 10 frames\n",
    "# Note: This logic assumes frame 0 is the start. Adjust indices if necessary.\n",
    "start_time = screen_device.timestamps[0]\n",
    "end_time = screen_device.timestamps[10] # or 9, depending on if you want inclusive/exclusive\n",
    "\n",
    "# Create a TimeInterval object\n",
    "interval = TimeInterval(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219d985c-7866-409d-9e22-d8e3cb9c40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling rates you want for the output (optional, defaults to config)\n",
    "# You might want to match the screen's native rate or a fixed rate like 30Hz\n",
    "target_rates = {\n",
    "    'screen': 30.0,      # Example: 30 Hz\n",
    "    'responses': 30.0,   # Match screen rate for easy alignment, or keep native\n",
    "    # 'behaviors': 30.0    # Match screen rate\n",
    "    'eye_tracker': 30.0,  # Add specific device names found in your experiment\n",
    "    'treadmill': 30.0\n",
    "}\n",
    "\n",
    "# Fetch the data\n",
    "# This returns a dictionary with keys like 'screen', 'responses', etc.\n",
    "subset_data = experiment.get_data_for_interval(\n",
    "    interval,\n",
    "    target_sampling_rates=target_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c186af67-66aa-417d-82ca-589b6d2ab8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_dataset_to_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     26\u001b[39m export_data[\u001b[33m'\u001b[39m\u001b[33mstatistics\u001b[39m\u001b[33m'\u001b[39m] = {\n\u001b[32m     27\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mresponses\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     28\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m: np.mean(subset_data[\u001b[33m'\u001b[39m\u001b[33mresponses\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m0\u001b[39m),\n\u001b[32m     29\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m: np.std(subset_data[\u001b[33m'\u001b[39m\u001b[33mresponses\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m0\u001b[39m)\n\u001b[32m     30\u001b[39m     }\n\u001b[32m     31\u001b[39m }\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 3. Save the dataset including metadata\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Note: You don't need to add 'tiers', 'neurons', etc. to data_keys \u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# if you use the default logic, but it's safer to be explicit if you are filtering.\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# However, `save_to_folder` has hardcoded checks for these specific meta keys \u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# separate from the `data_keys` loop.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43msave_dataset_to_folder\u001b[49m(\n\u001b[32m     39\u001b[39m     data=export_data,\n\u001b[32m     40\u001b[39m     full_path=\u001b[33m'\u001b[39m\u001b[33m./my_dataset_with_meta\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     41\u001b[39m     overwrite=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# data_keys usually controls the \"data\" folder content. \u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Metadata keys are handled automatically if present in the dictionary.\u001b[39;00m\n\u001b[32m     44\u001b[39m     data_keys=[\u001b[33m'\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mresponses\u001b[39m\u001b[33m'\u001b[39m] \n\u001b[32m     45\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'save_dataset_to_folder' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the dictionary for the exporter\n",
    "export_data = {\n",
    "    'images': subset_data['screen'],        # Map 'screen' to 'images'\n",
    "    'responses': subset_data['responses'],  # Keep 'responses'\n",
    "    'behavior': subset_data.get('eye_tracker'), # Map 'behaviors' (if it exists)\n",
    "    'behavior': subset_data.get('treadmill'), # Map 'behaviors' (if it exists)\n",
    "    # Add other keys if necessary, like 'pupil_center' if available\n",
    "}\n",
    "\n",
    "# 2. Add Metadata\n",
    "# Example: Adding trial tiers (e.g., 'train', 'test', 'validation')\n",
    "# Since we have 10 frames, we need 10 entries if this is per-frame metadata,\n",
    "# or it might be per-trial depending on how you define a \"trial\".\n",
    "# Assuming 1-to-1 mapping with the 'images' dimension:\n",
    "export_data['tiers'] = np.array(['train'] * 10) \n",
    "\n",
    "# Example: Adding Neuron Metadata (e.g., cell locations, ids)\n",
    "# This should match the second dimension of your 'responses' (n_neurons)\n",
    "n_neurons = subset_data['responses'].shape[1]\n",
    "export_data['neurons'] = {\n",
    "    'cell_ids': np.arange(n_neurons),\n",
    "    'cell_types': np.array(['excitatory'] * n_neurons) \n",
    "}\n",
    "\n",
    "# Example: Adding Statistics (e.g., mean/std of the original data)\n",
    "export_data['statistics'] = {\n",
    "    'responses': {\n",
    "        'mean': np.mean(subset_data['responses'], axis=0),\n",
    "        'std': np.std(subset_data['responses'], axis=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Save the dataset including metadata\n",
    "# Note: You don't need to add 'tiers', 'neurons', etc. to data_keys \n",
    "# if you use the default logic, but it's safer to be explicit if you are filtering.\n",
    "# However, `save_to_folder` has hardcoded checks for these specific meta keys \n",
    "# separate from the `data_keys` loop.\n",
    "save_dataset_to_folder(\n",
    "    data=export_data,\n",
    "    full_path='./my_dataset_with_meta',\n",
    "    overwrite=True,\n",
    "    # data_keys usually controls the \"data\" folder content. \n",
    "    # Metadata keys are handled automatically if present in the dictionary.\n",
    "    data_keys=['images', 'responses'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336b97b-aed9-4c17-9f61-fe788754ef57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
