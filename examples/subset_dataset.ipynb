{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2028402d-9351-471e-82f2-4d9a5e5df719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path if needed\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885fc14a-308a-4190-99a1-0dd16859dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "from experanto.datasets import ChunkDataset\n",
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "\n",
    "from nexport.exporters.utils.storage import save_dataset_to_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdae3976-97ef-48e1-86ad-23e4058a2cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "  global_sampling_rate: null\n",
      "  global_chunk_size: null\n",
      "  add_behavior_as_channels: false\n",
      "  replace_nans_with_means: false\n",
      "  cache_data: false\n",
      "  out_keys:\n",
      "  - screen\n",
      "  - responses\n",
      "  - eye_tracker\n",
      "  - treadmill\n",
      "  - timestamps\n",
      "  normalize_timestamps: true\n",
      "  modality_config:\n",
      "    screen:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      valid_condition:\n",
      "        tier: train\n",
      "      offset: 0\n",
      "      sample_stride: 1\n",
      "      include_blanks: true\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "        Resize:\n",
      "          _target_: torchvision.transforms.v2.Resize\n",
      "          size:\n",
      "          - 144\n",
      "          - 256\n",
      "      interpolation:\n",
      "        rescale: true\n",
      "        rescale_size:\n",
      "        - 144\n",
      "        - 256\n",
      "    responses:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 8\n",
      "      chunk_size: 16\n",
      "      offset: 0.0\n",
      "      transforms:\n",
      "        normalization: standardize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "    eye_tracker:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      offset: 0\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "    treadmill:\n",
      "      keep_nans: false\n",
      "      sampling_rate: 30\n",
      "      chunk_size: 60\n",
      "      offset: 0\n",
      "      transforms:\n",
      "        normalization: normalize\n",
      "      interpolation:\n",
      "        interpolation_mode: nearest_neighbor\n",
      "      filters:\n",
      "        nan_filter:\n",
      "          __target__: experanto.filters.common_filters.nan_filter\n",
      "          __partial__: true\n",
      "          vicinity: 0.05\n",
      "dataloader:\n",
      "  batch_size: 16\n",
      "  shuffle: true\n",
      "  num_workers: 2\n",
      "  pin_memory: true\n",
      "  drop_last: true\n",
      "  prefetch_factor: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30422f76-e0ce-4ccf-9aaa-212489cfe067",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.modality_config.screen.include_blanks = True\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"train\"}\n",
    "cfg.dataloader.num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553daf92-07bf-49b4-86b5-11331f49856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata file found at /data/dynamic29513-3-5-Video-full/meta.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "\n",
    "paths = [\"/data/dynamic29513-3-5-Video-full\"]\n",
    "train_dl = get_multisession_dataloader(paths, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eebba7b-eb53-44a5-be94-ace0af38096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.experiment import Experiment\n",
    "from experanto.configs import DEFAULT_MODALITY_CONFIG\n",
    "\n",
    "# Define the path to your experiment data\n",
    "root_folder = '/data/dynamic29513-3-5-Video-full'\n",
    "\n",
    "# Initialize the experiment\n",
    "experiment = Experiment(root_folder, modality_config=DEFAULT_MODALITY_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc49e43-67ef-48f8-bc3f-2418a16adf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from experanto.intervals import TimeInterval\n",
    "\n",
    "# Access the screen device to find the timestamps of the first 10 frames\n",
    "screen_device = experiment.devices['screen']\n",
    "\n",
    "# Assuming screen timestamps are available and sorted\n",
    "# Get the start and end time for the first 10 frames\n",
    "# Note: This logic assumes frame 0 is the start. Adjust indices if necessary.\n",
    "start_time = screen_device.timestamps[0]\n",
    "end_time = screen_device.timestamps[10] # or 9, depending on if you want inclusive/exclusive\n",
    "\n",
    "# Create a TimeInterval object\n",
    "interval = TimeInterval(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219d985c-7866-409d-9e22-d8e3cb9c40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling rates you want for the output (optional, defaults to config)\n",
    "# You might want to match the screen's native rate or a fixed rate like 30Hz\n",
    "target_rates = {\n",
    "    'screen': 30.0,      # Example: 30 Hz\n",
    "    'responses': 30.0,   # Match screen rate for easy alignment, or keep native\n",
    "    # 'behaviors': 30.0    # Match screen rate\n",
    "    'eye_tracker': 30.0,  # Add specific device names found in your experiment\n",
    "    'treadmill': 30.0\n",
    "}\n",
    "\n",
    "# Fetch the data\n",
    "# This returns a dictionary with keys like 'screen', 'responses', etc.\n",
    "subset_data = experiment.get_data_for_interval(\n",
    "    interval,\n",
    "    target_sampling_rates=target_rates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c186af67-66aa-417d-82ca-589b6d2ab8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving screen: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 247.06it/s]\n",
      "Saving responses: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 239.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-12-2025:15:47:52 INFO     storage.py            84:\t Saving my_dataset_with_meta/meta/trials/tiers.npy\n",
      "11-12-2025:15:47:52 INFO     storage.py            84:\t Saving my_dataset_with_meta/meta/neurons/cell_ids.npy\n",
      "11-12-2025:15:47:52 INFO     storage.py            84:\t Saving my_dataset_with_meta/meta/neurons/cell_types.npy\n",
      "11-12-2025:15:47:52 INFO     storage.py            84:\t Saving my_dataset_with_meta/meta/statistics/responses/mean.npy\n",
      "11-12-2025:15:47:52 INFO     storage.py            84:\t Saving my_dataset_with_meta/meta/statistics/responses/std.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary for the exporter\n",
    "export_data = {\n",
    "    'screen': subset_data['screen'],\n",
    "    'responses': subset_data['responses'],  # Keep 'responses'\n",
    "    'behavior': subset_data.get('eye_tracker'), # Map 'behaviors' (if it exists)\n",
    "    'behavior': subset_data.get('treadmill'), # Map 'behaviors' (if it exists)\n",
    "    # Add other keys if necessary, like 'pupil_center' if available\n",
    "}\n",
    "\n",
    "# 2. Add Metadata\n",
    "# Example: Adding trial tiers (e.g., 'train', 'test', 'validation')\n",
    "# Since we have 10 frames, we need 10 entries if this is per-frame metadata,\n",
    "# or it might be per-trial depending on how you define a \"trial\".\n",
    "# Assuming 1-to-1 mapping with the 'screen' dimension:\n",
    "export_data['tiers'] = np.array(['train'] * 10) \n",
    "\n",
    "# Example: Adding Neuron Metadata (e.g., cell locations, ids)\n",
    "# This should match the second dimension of your 'responses' (n_neurons)\n",
    "n_neurons = subset_data['responses'].shape[1]\n",
    "export_data['neurons'] = {\n",
    "    'cell_ids': np.arange(n_neurons),\n",
    "    'cell_types': np.array(['excitatory'] * n_neurons) \n",
    "}\n",
    "\n",
    "# This dictionary is expected by save_to_folder.\n",
    "export_data['item_info'] = {}\n",
    "\n",
    "# Example: Adding Statistics (e.g., mean/std of the original data)\n",
    "export_data['statistics'] = {\n",
    "    'responses': {\n",
    "        'mean': np.mean(subset_data['responses'], axis=0),\n",
    "        'std': np.std(subset_data['responses'], axis=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Save the dataset including metadata\n",
    "# Note: You don't need to add 'tiers', 'neurons', etc. to data_keys \n",
    "# if you use the default logic, but it's safer to be explicit if you are filtering.\n",
    "# However, `save_to_folder` has hardcoded checks for these specific meta keys \n",
    "# separate from the `data_keys` loop.\n",
    "save_dataset_to_folder(\n",
    "    data=export_data,\n",
    "    full_path='./my_dataset_with_meta',\n",
    "    overwrite=True,\n",
    "    # data_keys usually controls the \"data\" folder content. \n",
    "    # Metadata keys are handled automatically if present in the dictionary.\n",
    "    data_keys=['screen', 'responses'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3336b97b-aed9-4c17-9f61-fe788754ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Configuration:\n",
      "responses:\n",
      "  keep_nans: false\n",
      "  sampling_rate: 8\n",
      "  chunk_size: 16\n",
      "  offset: 0.0\n",
      "  transforms:\n",
      "    normalization: standardize\n",
      "  interpolation:\n",
      "    interpolation_mode: nearest_neighbor\n",
      "  filters:\n",
      "    nan_filter:\n",
      "      __target__: experanto.filters.common_filters.nan_filter\n",
      "      __partial__: true\n",
      "      vicinity: 0.05\n",
      "eye_tracker:\n",
      "  keep_nans: false\n",
      "  sampling_rate: 30\n",
      "  chunk_size: 60\n",
      "  offset: 0\n",
      "  transforms:\n",
      "    normalization: normalize\n",
      "  interpolation:\n",
      "    interpolation_mode: nearest_neighbor\n",
      "  filters:\n",
      "    nan_filter:\n",
      "      __target__: experanto.filters.common_filters.nan_filter\n",
      "      __partial__: true\n",
      "      vicinity: 0.05\n",
      "treadmill:\n",
      "  keep_nans: false\n",
      "  sampling_rate: 30\n",
      "  chunk_size: 60\n",
      "  offset: 0\n",
      "  transforms:\n",
      "    normalization: normalize\n",
      "  interpolation:\n",
      "    interpolation_mode: nearest_neighbor\n",
      "  filters:\n",
      "    nan_filter:\n",
      "      __target__: experanto.filters.common_filters.nan_filter\n",
      "      __partial__: true\n",
      "      vicinity: 0.05\n",
      "images:\n",
      "  keep_nans: false\n",
      "  sampling_rate: 30\n",
      "  chunk_size: 60\n",
      "  valid_condition:\n",
      "    tier: train\n",
      "  offset: 0\n",
      "  sample_stride: 1\n",
      "  include_blanks: true\n",
      "  transforms:\n",
      "    normalization: normalize\n",
      "    Resize:\n",
      "      _target_: torchvision.transforms.v2.Resize\n",
      "      size:\n",
      "      - 144\n",
      "      - 256\n",
      "  interpolation:\n",
      "    rescale: true\n",
      "    rescale_size:\n",
      "    - 144\n",
      "    - 256\n",
      "\n",
      "No metadata file found at /project/examples/my_dataset_with_meta/meta.json\n",
      "\n",
      "Error loading dataset: Missing key screen\n",
      "    full_key: dataset.modality_config.screen\n",
      "    object_type=dict\n",
      "Ensure the exported folder contains the 'meta.yml' files required by Experanto.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Import experanto modules\n",
    "from experanto.configs import DEFAULT_CONFIG as cfg\n",
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "\n",
    "# 1. Define the path to your exported dataset\n",
    "# This matches the 'full_path' used in the previous save_dataset_to_folder step\n",
    "dataset_path = str(Path('./my_dataset_with_meta').absolute())\n",
    "\n",
    "# 2. Modify the Configuration\n",
    "# The default config expects a 'screen' modality. \n",
    "# If your export folder is named 'images' (from the previous step), \n",
    "# we need to copy the screen configuration to an 'images' key.\n",
    "if 'screen' in cfg.dataset.modality_config:\n",
    "    # Copy default screen config to 'images' key to match folder name\n",
    "    cfg.dataset.modality_config.images = cfg.dataset.modality_config.screen\n",
    "    # Optional: Remove 'screen' if it doesn't exist on disk to avoid warnings\n",
    "    del cfg.dataset.modality_config.screen\n",
    "\n",
    "# Update 'images' specific settings (formerly screen)\n",
    "cfg.dataset.modality_config.images.include_blanks = True\n",
    "# Ensure the valid_condition matches metadata you saved (e.g., you saved 'tiers'=['train'])\n",
    "cfg.dataset.modality_config.images.valid_condition = {\"tier\": \"train\"}\n",
    "\n",
    "# Update 'responses' settings if needed\n",
    "if 'responses' in cfg.dataset.modality_config:\n",
    "    # Adjust sampling rate if your exported data is already subsampled or different\n",
    "    # cfg.dataset.modality_config.responses.sampling_rate = 30 \n",
    "    pass\n",
    "\n",
    "# Set dataloader parameters\n",
    "cfg.dataloader.num_workers = 0 # Set to 0 for debugging/local tests, increase for speed later\n",
    "cfg.dataloader.batch_size = 4\n",
    "\n",
    "print(\"Loading Configuration:\")\n",
    "print(OmegaConf.to_yaml(cfg.dataset.modality_config))\n",
    "\n",
    "# 3. Instantiate the Dataloader\n",
    "# get_multisession_dataloader expects a list of paths\n",
    "try:\n",
    "    train_dl = get_multisession_dataloader([dataset_path], cfg)\n",
    "    print(f\"Successfully created dataloader with {len(train_dl)} batches.\")\n",
    "\n",
    "    # 4. Test loading a batch\n",
    "    iterator = iter(train_dl)\n",
    "    dataset_key, batch = next(iterator)\n",
    "\n",
    "    print(f\"\\nLoaded batch from dataset: {dataset_key}\")\n",
    "    for key, value in batch.items():\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"Modality: {key:<15} Shape: {value.shape}\")\n",
    "        else:\n",
    "            print(f\"Modality: {key:<15} Type: {type(value)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading dataset: {e}\")\n",
    "    print(\"Ensure the exported folder contains the 'meta.yml' files required by Experanto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301af028-b55c-460b-b202-4fc86b0662bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
