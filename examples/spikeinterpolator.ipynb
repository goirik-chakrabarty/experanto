{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41c395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataLoader...\n",
      "No metadata file found at /mnt/vast-nhr/projects/nix00014/goirik/data/dummy2/meta.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'screen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# 4. Create Dataloader\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Returns a LongCycler wrapping the individual dataloaders\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating DataLoader...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m loader = \u001b[43mget_multisession_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_obj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# 5. Iterate\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIterating...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/vast-nhr/projects/nix00014/goirik/experanto_goirik/experanto/dataloaders.py:56\u001b[39m, in \u001b[36mget_multisession_dataloader\u001b[39m\u001b[34m(paths, configs, shuffle_keys, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     55\u001b[39m         dataset_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msession_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     dataset = \u001b[43mChunkDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     dataloaders[dataset_name] = MultiEpochsDataLoader(\n\u001b[32m     58\u001b[39m         dataset,\n\u001b[32m     59\u001b[39m         **cfg.dataloader,\n\u001b[32m     60\u001b[39m     )\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LongCycler(dataloaders)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/vast-nhr/projects/nix00014/goirik/experanto_goirik/experanto/datasets.py:209\u001b[39m, in \u001b[36mChunkDataset.__init__\u001b[39m\u001b[34m(self, root_folder, global_sampling_rate, global_chunk_size, add_behavior_as_channels, replace_nans_with_means, cache_data, out_keys, normalize_timestamps, modality_config, seed, safe_interval_threshold)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.start_time >= \u001b[38;5;28mself\u001b[39m.end_time:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    203\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo valid overlapping time interval found across all devices after applying safety threshold. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal range: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_end_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msafe_interval_threshold\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdjusted range: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.end_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m.initialize_statistics()\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._screen_sample_times = np.arange(\n\u001b[32m    212\u001b[39m     \u001b[38;5;28mself\u001b[39m.start_time, \u001b[38;5;28mself\u001b[39m.end_time, \u001b[32m1.0\u001b[39m / \u001b[38;5;28mself\u001b[39m.sampling_rates[\u001b[33m\"\u001b[39m\u001b[33mscreen\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    213\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/vast-nhr/projects/nix00014/goirik/experanto_goirik/experanto/datasets.py:233\u001b[39m, in \u001b[36mChunkDataset._read_trials\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_trials\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     screen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_experiment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscreen\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    234\u001b[39m     \u001b[38;5;28mself\u001b[39m._trials = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m screen.trials]\n\u001b[32m    235\u001b[39m     start_idx = np.array([t.first_frame_idx \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trials])\n",
      "\u001b[31mKeyError\u001b[39m: 'screen'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# 1. Setup paths\n",
    "base_path = Path(\"/mnt/vast-nhr/projects/nix00014/goirik/data/dummy2\")\n",
    "spikes_path = base_path / \"responses\"\n",
    "if spikes_path.exists():\n",
    "    shutil.rmtree(spikes_path)\n",
    "spikes_path.mkdir()\n",
    "\n",
    "# 2. Create Dummy Data (Spikes + Meta)\n",
    "n_neurons = 500\n",
    "duration = 100.0\n",
    "all_spikes = []\n",
    "indices = [0]\n",
    "\n",
    "for _ in range(n_neurons):\n",
    "    n_spikes = int(duration * 20)  # 20 Hz\n",
    "    spikes = np.sort(np.random.uniform(0, duration, n_spikes))\n",
    "    all_spikes.append(spikes)\n",
    "    indices.append(indices[-1] + len(spikes))\n",
    "\n",
    "flat_spikes = np.concatenate(all_spikes)\n",
    "flat_spikes.tofile(spikes_path / \"spikes.npy\")\n",
    "\n",
    "meta = {\n",
    "    \"modality\": \"spikes\",\n",
    "    \"n_signals\": n_neurons,\n",
    "    \"spike_indices\": indices,\n",
    "    \"start_time\": 0.0,\n",
    "    \"end_time\": duration,\n",
    "    \"sampling_rate\": 1000.0 \n",
    "}\n",
    "\n",
    "with open(spikes_path / \"meta.yml\", \"w\") as f:\n",
    "    yaml.dump(meta, f)\n",
    "\n",
    "# 3. Define Configs\n",
    "# Note: ChunkDataset/get_multisession_dataloader usually requires a configuration \n",
    "# specifying 'dataset' parameters (passed to ChunkDataset) and 'dataloader' parameters.\n",
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"global_chunk_size\": 8, \n",
    "        \"global_sampling_rate\": 30,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"out_keys\": [\"responses\"],\n",
    "        \n",
    "        \"modality_config\": {\n",
    "            \"spike\": {\n",
    "                \"chunk_size\": 40,\n",
    "                \"sampling_rate\": 20,\n",
    "                \"interpolation\": {\n",
    "                    \"interpolation_window\": 0.5,\n",
    "                    \"interpolation_align\": \"center\",\n",
    "                }, \n",
    "            },\n",
    "            \"screen\": {\n",
    "                \"chunk_size\": 60,\n",
    "                \"sampling_rate\": 30,\n",
    "                \"sample_stride\": 1,\n",
    "                \"interpolation\": {\n",
    "                    \"interpolation_mode\": \"nearest_neighbor\",\n",
    "                },   \n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"dataloader\": {\n",
    "        \"batch_size\": 16,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 2,\n",
    "        \"drop_last\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "config_obj = OmegaConf.create(config)\n",
    "\n",
    "# 4. Create Dataloader\n",
    "# Returns a LongCycler wrapping the individual dataloaders\n",
    "print(\"Creating DataLoader...\")\n",
    "loader = get_multisession_dataloader(\n",
    "    paths=[str(base_path)],\n",
    "    configs=[config_obj]\n",
    ")\n",
    "\n",
    "# 5. Iterate\n",
    "print(\"Iterating...\")\n",
    "for batch in loader:\n",
    "    # 'batch' is typically a namedtuple or dict depending on ChunkDataset implementation\n",
    "    # It usually contains 'inputs', 'targets', etc.\n",
    "    print(f\"Loaded batch keys: {batch.keys()}\") \n",
    "    # Assuming the interpolator returns the data as the main signal:\n",
    "    print(f\"Data shape: {batch['inputs'].shape if 'inputs' in batch else batch}\")\n",
    "    break\n",
    "\n",
    "# Cleanup\n",
    "# shutil.rmtree(base_path)\n",
    "# This will not work until I make a dummy dataset with screen data as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412b8f4",
   "metadata": {},
   "source": [
    "# Initializing experiments works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b43ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94ff849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"dataset\": {\n",
    "        \"global_chunk_size\": 8, \n",
    "        \"global_sampling_rate\": 30,\n",
    "        \"add_behavior_as_channels\": False,\n",
    "        \"out_keys\": [\"responses\"],\n",
    "        \n",
    "        \"modality_config\": {\n",
    "            \"spike\": {\n",
    "                \"chunk_size\": 40,\n",
    "                \"sampling_rate\": 20,\n",
    "                \"interpolation\": {\n",
    "                    \"interpolation_window\": 0.5,\n",
    "                    \"interpolation_align\": \"center\",\n",
    "                }, \n",
    "            },\n",
    "            \"screen\": {\n",
    "                \"chunk_size\": 60,\n",
    "                \"sampling_rate\": 30,\n",
    "                \"sample_stride\": 1,\n",
    "                \"interpolation\": {\n",
    "                    \"interpolation_mode\": \"nearest_neighbor\",\n",
    "                },   \n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"dataloader\": {\n",
    "        \"batch_size\": 16,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 2,\n",
    "        \"drop_last\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "config_obj = OmegaConf.create(config)\n",
    "\n",
    "\n",
    "experiment = Experiment(root_folder=base_path,\n",
    "        modality_config= config[\"dataset\"][\"modality_config\"],\n",
    "        cache_data=True,\n",
    "        interpolate_precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad42f9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spike',)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.device_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experanto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
